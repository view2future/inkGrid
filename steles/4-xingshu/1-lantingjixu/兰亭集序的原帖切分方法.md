# 兰亭集序的原帖切分方法（规划与决策记录）

- 项目：墨阵 / inkGrid
- 目标：把王羲之《兰亭集序》（原帖 4 张页图）切成“每字一图”，并生成稳定索引，便于后续“一字多形”等功能。
- 输入原帖：`steles/4-xingshu/1-lantingjixu/lantingjixu-1.jpg` ~ `lantingjixu-4.jpg`
- 参考规范：曹全碑切字规范与索引结构（`steles/2-lishu/1-caoquanbei/chars_yang/README.md`、`index.json`、`scripts/extract_caoquanbei_chars.py`）

> 说明：用户要求记录“完整思考过程”。出于可复现与可公开原则，本文记录的是**对外可公开的分析步骤与决策依据**（等价于工程日志/设计推导），不包含任何模型内部隐私推理细节。

---

## 1) Thinking Process (Public, English)

### 1.1 What I inspected in the repo
1. Checked the existing character-slicing dataset structure for Caoquanbei:
   - Naming convention: `caoquanbei_yang_{index:04d}_U{codepoint}.png`
   - Index format: `index.json` with per-file metadata (char, codepoint, source image, grid position, crop box)
2. Checked the existing extraction script:
   - `scripts/extract_caoquanbei_chars.py` uses a fixed grid (3 cols x 6 rows), with a known reading order.

### 1.2 What I inspected in the Lanting images
1. Opened the four page images under `steles/4-xingshu/1-lantingjixu/`.
2. Observations:
   - Vertical columns (traditional reading order).
   - Non-uniform layout: not a strict grid; character spacing varies.
   - Multiple red seals and at least one heavy occlusion (a large dark patch), which can break purely vision-based segmentation.

### 1.3 Quick quantitative checks (to choose an algorithm)
1. I used a projection-based estimator to approximate the number of text columns per page.
2. Key idea:
   - Build an “ink mask” using a grayscale threshold (dark pixels).
   - Exclude red seals using an RGB heuristic (high R relative to G/B).
   - Sum ink pixels along the x-axis; segments above a threshold correspond to columns.
3. Rough result (page -> estimated columns):
   - page1 ~ 6
   - page2 ~ 7
   - page3 ~ 8
   - page4 ~ 7
   - Total ~ 28 columns
4. I also tried a naive per-column y-projection to estimate per-column character counts.
   - The totals were not stable in that crude pass, confirming:
     - pure vision-only segmentation will drift and accumulate errors
     - we must constrain segmentation using a reference transcription (per-column character count).

### 1.4 Core decisions
1. Keep output naming and indexing aligned with the Caoquanbei dataset for later retrieval:
   - Output directory: `steles/4-xingshu/1-lantingjixu/chars_shenlong/` (versioned by source edition)
   - Per-char PNG: `lantingjixu_shenlong_{index:04d}_U{codepoint}.png`
   - Index: `index.json` + `text.txt`
2. Use a two-stage segmentation approach:
   - Stage A: segment columns via x-projection (robust to variable spacing)
   - Stage B: segment characters within each column by using the known line length (N) from the transcription:
     - start with equal-height splits
     - snap each split line to nearby y-projection valleys
3. Provide a manual correction mechanism:
   - `overrides.json` to handle occlusions (seals/dark patch), merges/splits, and per-column adjustments.
4. Support two output “rendering modes” (optional but useful later):
   - `raw`: keep paper texture (aesthetic / archival)
   - `ink`: isolate ink stroke (better for comparing shapes and search)

---

## 2) 思考过程（中文译，可公开复现版）

### 2.1 我在仓库里先对齐了“曹全碑切字”规范
1. 查了曹全碑切字目录与命名规则：
   - 文件名：`caoquanbei_yang_{index:04d}_U{codepoint}.png`
   - 索引：`index.json` 记录每张字图对应的字、Unicode、来源页图、以及裁剪框等元信息
2. 读了脚本 `scripts/extract_caoquanbei_chars.py`：
   - 曹全碑属于“规则网格”切分（3列×6行），读序固定，因此能纯规则批处理。

### 2.2 我对兰亭集序 4 张原帖做了版式判断
1. 逐张看了 `steles/4-xingshu/1-lantingjixu/lantingjixu-1..4.jpg`：
   - 都是竖排列书（传统读序）
   - 不是严格网格：列间距/字距有变化
   - 红印章很多、且存在明显遮挡（黑块/盖印），这会破坏“纯图像分割”的稳定性

### 2.3 我做了快速定量估计，用来决定切分算法
1. 用“投影法”快速估列数（并排除红印的干扰）：
   - 墨迹 mask：灰度阈值取暗像素
   - 红印排除：用 RGB 条件判断“R 明显高于 G/B”
   - x 方向投影：把每列当作一个“高密度段”
2. 粗估结果（每页列数）：
   - 第1页≈6列，第2页≈7列，第3页≈8列，第4页≈7列，总计≈28列
   - 这与兰亭集序常见的“28行版式”一致，因此“先切 28 列”是可靠的主策略
3. 我也尝试用每列的 y 投影粗估字数，发现结果不稳定（纯视觉会漂移）：
   - 结论：不能只靠视觉切分，必须用释文约束“每列应切 N 字”，否则错一处会累积错位。

### 2.4 核心决策（以及原因）
1. 命名规则与索引结构尽量贴近曹全碑，便于未来统一检索与“一字多形”：
   - `lantingjixu_shenlong_{index:04d}_U{codepoint}.png`
   - `index.json` + `text.txt`
2. 采用“两阶段 + 释文约束”的切分：
   - 阶段A：先切列（x投影找列段；按右到左排序）
   - 阶段B：每列按释文行长 N 切字格（先均分，再在每个切线附近吸附到 y 投影谷值）
3. 预留人工修正入口 `overrides.json`：
   - 红印/黑块遮挡、粘连/断裂导致的误切，靠少量 override 修正，保证最终可交付
4. 输出可选两种“渲染模式”：
   - `raw`（保留纸色，美观）
   - `ink`（提取墨迹，更利于形态对比/检索）

---

## 3) 最终中文回复（原文备份）

我先看了你给的 4 张原帖：它们都是竖排列书，按投影粗估分别是 6/7/8/7 列，总计正好 28 列（对应兰亭集序常见的 28 行布局）。这让“按列切字 + 按释文对齐”变成一个可稳定自动化的任务。

**目标产物（对齐曹全碑风格）**
- 输出目录：`steles/4-xingshu/1-lantingjixu/chars_shenlong/`（“神龙本”可换别名）
- 每字一张图（PNG）：`lantingjixu_shenlong_{index:04d}_U{codepoint}.png`
- `index.json`：每张字图的字/Unicode/来源页图/所在列与行/裁剪框/质量标记
- `text.txt`：按阅读顺序拼接的全文字符序列（用于“一字多形”检索与对齐）

**核心难点与策略**
- 难点：兰亭不是规则网格，且有红印、局部遮挡（你图里有明显盖印/黑块）。
- 策略：把“整张图切字”拆成两层结构：
  1) 先稳切 28 列（列边界用 x 方向投影/密度谷值找分隔）
  2) 再在每一列里按“该列应有的字数”切成 N 个字格（用 y 方向投影在预计分割点附近找谷值微调）
  这样可以用“释文每行字数”约束住切分，避免纯图像法把一个字切成两段/把噪声当字。

**执行流程规划**
1) **准备释文（关键）**
   - 拉取一个可靠版本的《兰亭集序》全文（优先繁体），并整理成“28 行”的行分割文本（每行对应一列）。
   - 校验：行数=28；总字数=324（或该版本实际字数）；首尾应能对应图中开头“永和九年…”与结尾“亦将有感于斯文”。

2) **自动检测列框**
   - 对每张 `lantingjixu-*.jpg`：
     - 生成“墨迹 mask”：低亮度像素作为墨迹；用颜色规则把红印章像素排除（红印会干扰投影/连通域）。
     - x 投影找列段，得到每列的 `[x0,x1]`（并按从右到左排序，符合阅读顺序）。

3) **按释文行长切字格**
   - 对每列：
     - 先取该列墨迹的 `[ymin,ymax]` 作为有效高度；
     - 已知该列应有 N 个字（来自第 1 步的“28 行释文”），用均分高度得到 N-1 个预计分割点；
     - 在每个预计点附近 ±窗口搜索 y 投影谷值，落到真实字间空隙；
     - 得到 N 个字格 `[y0,y1]`。

4) **字格内二次裁剪与归一化**
   - 对每个字格：
     - 在字格内做一次“紧边框”找真实笔画 bbox（避免字格太空/太松）
     - 统一输出尺寸（建议 512×512，可参数化），居中+内边距
     - 对红印/噪声：输出可选两种模式
       - `raw`：保留原纸色（美观、接近原帖）
       - `ink`：只保留墨迹（透明底/白底），更适合后续“一字多形”对比与检索

5) **生成索引与质检**
   - `index.json` 除基础字段外建议包含：
     - `page`、`col_in_page`、`line_index_global(1..28)`、`pos_in_line`、`crop_box`
     - `ink_pixel_count`/`is_occluded`（用于标记盖印或黑块导致的“空白/异常字”）
   - 质检脚本输出：
     - 总图片数是否等于释文字数
     - “疑似空白/过小/过大 bbox”的清单
     - 每页叠加框的 `debug_overlay_pageN.jpg` 便于肉眼抽查

6) **容错/人工修正通道（保证可交付）**
   - 预留 `overrides.json`：
     - 指定某列某个分割点上移/下移、合并/拆分、跳过（盖印/黑块处最常见）
   - 先跑全自动 → 看 debug/异常清单 → 只对少数问题点补 overrides → 再跑一次得到稳定数据集。

---

## 4) V1 问题复盘与 V2 改进方案（工程记录）

### 4.1 用户反馈的问题分类

用户对 V1 切字结果做了人工复查，并把问题分成三类：

1) **一张图里有 2 个字**（通常是相邻两个字被同一个裁剪框覆盖）
2) **边界截断**（字的笔画在边缘被裁掉，导致字不完整）
3) **没有字**（只有纸面纹理、红印、涂改，或仅有极小残笔）

### 4.2 我对 V1 结果做的定位分析（可复现）

基于 `steles/4-xingshu/1-lantingjixu/chars_shenlong---old/index.json` 的元信息（page/line/pos/crop_box）：

- **“边界截断”高频集中在第 2 张原帖（page2）**
- **“没有字”高频集中在第 4 张原帖（page4）**（红印更密集、遮挡更重）

另外，对部分“没有字”的样本，发现其 `crop_box` 高度异常小（例如 41px、45px），属于明显的纵向切分漂移/塌缩。

对“有 2 个字”的样本抽样（例如 `lantingjixu_shenlong_0011_U4E4B.png`），能看到“上一个字的尾部 + 本字”同时落在同一张裁剪图里，说明字间边界落在错误位置。

### 4.3 V1 的根因判断

V1 的切分核心是“在预计切线附近找 y 投影谷值”，并对边界做了一个 `min_gap` 的强制单调修正。实践表明：

- **谷值搜索在行草粘连处不够稳定**（字间并非总有清晰空白）
- **`min_gap` 修正会把误差累积推到列尾**，导致末尾若干格高度塌缩，从而出现“没有字/只剩残笔”的空白格
- 列内 margin 过大且未做“墨迹紧边框二次裁剪”，会放大“截断”问题

### 4.4 V2 的改进结论（要做什么）

V2 的目标是尽量消除三类问题，并保持**命名与索引稳定**（`index=1..324` 不变），便于后续“一字多形”检索与对齐。

V2 主要改动：

1) **列内纵向切分改为“可行域约束的顺序边界搜索”**
   - 每一条边界在选取时就保证“剩余空间足够分给后面的字格”，从算法层面避免塌缩。
2) **边界从“硬裁剪”改为“上下文 + 墨迹紧边框”**
   - 先在 cell 周围取少量上下文，再在上下文内做墨迹 bbox（排除红印）
   - 以 bbox + padding 作为最终裁剪框，显著减少笔画被截断。
3) **遮挡/黑块鲁棒性**
   - 在墨迹 mask 中识别并剔除“超大连通域暗块”，避免它主导投影。
4) **增加 QA/回归**
   - 输出每字的墨迹像素量/触边情况/连通域数量等指标
   - 将用户提供的问题名单作为回归用例，重切后做自动对比。
